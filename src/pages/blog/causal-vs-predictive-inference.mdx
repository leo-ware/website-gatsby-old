---
title: "Causal Inference vs Predictive Inference"
description: "How causal inference differs from predictive inference and what makes the problem hard"
slug: "/blog/causal-vs-predictive-inference"
tags:
    - causal-inference
    - intro
---

import Layout from "../../components/MDXLayout"
export default Layout

import { InlineMath } from 'react-katex'
import {X, Y} from "../../components/Variables"

In machine learning, the goal is usually to find a model that fits some data well. This is called predictive inference. Predicting sales revenue for next quarter, determining whether a given credit card transaction was fraudulent, or determining whether a piece of content was generated by AI are all examples of predictive inference. These are questions of the form, “If <X/> has these properties, does it also have (or what is the value of) <Y/> property?” They involve estimating an expression of the form <InlineMath math={"P(outcome | covariates)"}/> math here.

Causal inference is about determining how a system responds to intervention. Examples include evaluating the effectiveness of a new drug, determining whether a change to a website increased conversion, or whether a bank demonstrates bias in granting mortgages. In these problems, we want to determine whether changing some covariate would change an outcome variable. We can express these problems mathematically using the do-operator, which goes behind the conditioning bar and indicates that we are asking about what would happen if we intervened on some variable. For example, <InlineMath math={"P(outcome | covariates, \\text{do}(treatment))"}/>.

These problems are hard because of confounding. Sometimes, a variable will influence both the outcome and whether a unit receives treatment. If we are measuring the effectiveness of an expensive new drug, it could be that doctors only prescribe the drug to the most severe cases of the disease. This subpopulation might be less likely to recover generally. So, if we naively compare the population that took the drug with the population that didn’t, we might underestimate the effectiveness of the drug. In general, <InlineMath math={"P(Y | X) \\ne P(Y | \\text{do}(X))"} />.

The gold standard in causality is a randomized controlled trial. In the drug testing example, we could randomly assign half a study population to receive the drug and the other half to not receive it, eliminating (hopefully) the possibility of confounding. But, randomized controlled trials are often infeasible because of cost, ethical concerns, or lack of compliance. We cannot randomly assign 50% of a study population to smoke. In these cases, we need to figure out what the result of a randomized controlled trial would be given only observational data.

Unfortunately, it is never possible to prove that one variable exerts a causal effect on another just by looking at data. Correlation does not imply causation. But, if we are willing to make assumptions about what causal effects exist in a dataset, we can sometimes measure them. No causality in, no causality out.
